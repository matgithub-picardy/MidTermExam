{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb28d8-f57f-4eb0-ae07-f036bd0e4e04",
   "metadata": {},
   "source": [
    "# Examen de MidTerm\n",
    "\n",
    "L'accès à Internet n'est pas autorisé pendant l'examen. Vous devez utiliser uniquement le carnet de notes, que vous sauvegardez à la fin de l'examen au format PDF. Le fichier PDF doit ensuite être déposé dans l'espace Moodle dédié. N'oubliez pas de vérifier que le kernel est connecté (cercle blanc en haut à droite) et de le reconnecter si nécessaire.\n",
    "\n",
    "## Partie 1 : Questions théoriques (30 points)\n",
    "**Instructions:** Répondez aux questions suivantes en vous basant sur les concepts abordés dans les tutoriels vus en classe. Il suffit de double-cliquer sur la case où vous voulez mettre votre réponse et d'appuyer sur les touches « Shift-Enter » pour valider votre réponse.\n",
    "\n",
    "(5 points) Quel est le rôle de la bibliothèque BeautifulSoup dans le web scraping, et comment interagit-elle avec urlopen ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edaeeb-846d-4301-841c-6b99241722e8",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8d832-d5e0-444e-9107-a2c3362b7128",
   "metadata": {},
   "source": [
    "(5 points) Qu'entend-on par « parsing » dans le cadre du « web scraping » ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d768f-5460-4e0b-aa83-53eac46aaed3",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49d8f7-72ab-46a6-933c-c40817506cf0",
   "metadata": {},
   "source": [
    "(5 points) Quelle est la différence entre ``find()`` et ``find_all()`` dans BeautifulSoup ? Donnez un exemple pour chacune d'entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e9364-5d66-4e34-a4de-b4e942f20dc0",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea421e-4961-4eca-ae8f-d0e0aa37c63b",
   "metadata": {},
   "source": [
    "(5 points) Expliquez comment les expressions régulières peuvent être utiles dans le web scraping. Donnez un exemple simple de regex utilisé dans l'un des tutoriels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b433c7b-9014-4849-ba62-7ae38db08a5e",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27dc6b-229b-40d3-bad2-4420c8a90c46",
   "metadata": {},
   "source": [
    "(5 points) Discutez des considérations éthiques liées au « web scraping ». Dans quels cas le scraping peut-il être considéré comme inapproprié ou illégal ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2efa47-2fb9-40f6-86be-2e30fbea1a4b",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859ef26-135f-45a1-9e86-4c4332413601",
   "metadata": {},
   "source": [
    "(5 points) Dans le cadre d'un projet de web scraping, vous souhaitez collecter des données à partir de plusieurs pages liées. Décrivez la stratégie que vous utiliseriez pour naviguer et collecter des données à partir de toutes les pages pertinentes sans supprimer les liens inutiles (par exemple, les pages « à propos », les pages « contact », etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d1642-096f-42ff-a603-a80e87c961f7",
   "metadata": {},
   "source": [
    "**Votre réponse ici:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f725e-b906-4fa8-979a-0d84a0fb48db",
   "metadata": {},
   "source": [
    "## Partie 2 : Questions pratiques (70 points)\n",
    "**Instructions:** Effectuez les exercices de codage suivants. Les codes fournis ici se réfèrent uniquement aux tutoriels 1 et 2 vus en classe. \n",
    "\n",
    "### Extraire des données d'une page Wikipedia (20 points)\n",
    "\n",
    "Récupérez le premier paragraphe de la page Wikipédia française « Kim Wilde » (/wiki/Kim_Wilde). Ensuite, extrayez et imprimez tous les liens internes (liens commençant par /wiki/) de la page en utilisant BeautifulSoup.\n",
    "\n",
    "Pour vous aider, vous trouverez ci-dessous trois éléments de code qui vous permettent de :\n",
    "- d'obtenir de l'aide sur une méthode ou une fonction\n",
    "- visualiser le rendu d'une page web directement dans le notebook\n",
    "- d'éditer le code html d'une page dans le carnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c4282-f476-4e04-8b21-2738bc06f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(BeautifulSoup.find_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425f8d0-13e8-4211-a2b2-bf58842ce1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Fetch the HTML content\n",
    "url = 'https://fr.wikipedia.org/wiki/Kevin_Bacon'\n",
    "html_content = urlopen(url).read().decode('utf-8')\n",
    "\n",
    "# Display the HTML content in the notebook\n",
    "HTML(html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b21f2a-4f14-4a65-83c4-90e57b876926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# Fetch the HTML content\n",
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "html_content = urlopen(url).read().decode('utf-8')\n",
    "\n",
    "# Display the raw HTML code\n",
    "print(html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84105f44-c421-47d9-a320-82a02fcdc282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen('https://fr.wikipedia.org/wiki/Kevin_Bacon')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Extract the first paragraph\n",
    "first_paragraph = bs.find('p')[6].get_text()\n",
    "print('Find here the 1st paragraph:', first_paragraph)\n",
    "\n",
    "# Extract internal links\n",
    "internal_links = bs.find_all('a', href=re.compile('^(/wiki/)'))\n",
    "for link in internal_links:\n",
    "    print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6acaea-92c0-48e4-98cb-324bf7c9eaf2",
   "metadata": {},
   "source": [
    "### Modifier le robot d'exploration (20 points)\n",
    "\n",
    "Écrivez un crawler qui part de la page Wikipédia « Kim wilde » et récupère tous les liens vers les articles (/wiki/) jusqu'à un niveau de profondeur 1. Veillez à éviter de récupérer des pages qui ne sont pas des articles, telles que les pages « Category » et « Talk »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b290bbe-d025-49b3-919f-abd7c263a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def getLinks(articleUrl, pages, depth=2):\n",
    "    if depth == 0:\n",
    "        return\n",
    "    html = urlopen(f'http://en.wikipedia.org{articleUrl}')\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    for link in bs.find('div', {'id':'bodyContent'}).find_all('a', href=re.compile('^(/wiki/)((?!:).)*$')):\n",
    "        if 'href' in link.attrs and link.attrs['href'] not in pages:\n",
    "            newPage = link.attrs['href']\n",
    "            print(newPage)\n",
    "            pages.add(newPage)\n",
    "            getLinks(newPage, pages, depth-1)\n",
    "\n",
    "pages = set()\n",
    "getLinks('/wiki/Kevin_Bacon', pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed62ae-c199-4e53-bc3e-34e0427d213b",
   "metadata": {},
   "source": [
    "### Recherche avancée par expression régulière (15 points)\n",
    "\n",
    "Modifiez le code pour trouver tous les paragraphes de la page « War and Peace » qui contiennent l'expression exacte « Prince ». N'imprimez que les paragraphes contenant l'expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d41434-8831-4cd2-a09a-22e7515a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Open the URL and parse the HTML content\n",
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all paragraphs containing the exact phrase \"Prince\" (case insensitive)\n",
    "paragraphs = bs.find_all(['p', 'div'], string=re.compile(r'\\bThe prince\\b'))\n",
    "\n",
    "# Print only the paragraphs containing the exact phrase\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ce641-baf6-4c4e-998a-e71a3d2ad32a",
   "metadata": {},
   "source": [
    "### Gestion des erreurs (15 points)\n",
    "\n",
    "Écrivez une fonction Python qui tente d'ouvrir une page web. Si la page n'existe pas ou s'il y a une erreur d'URL, la fonction doit afficher un message d'erreur. Traitez les erreurs avec \"élégance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724de0e-af99-4727-b3e4-72b3b6d97153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getPage(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        return bs\n",
    "    except HTTPError as e:\n",
    "        print(\"The server returned an HTTP error.\")\n",
    "    except URLError as e:\n",
    "        print(\"The server could not be found!\")\n",
    "    return None\n",
    "\n",
    "bs = getPage('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "if bs:\n",
    "    print(bs.h1.get_text())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
